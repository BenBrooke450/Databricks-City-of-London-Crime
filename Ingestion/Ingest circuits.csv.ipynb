{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10e81ff-516b-4937-9c15-b4c3a3e33ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ingest .csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19bbbd8-2d5c-44a8-a1c6-9b4dab473afb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DataType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb2dfb1-106d-4385-9f19-d8a1d31d63e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"/mnt/bronze/Electric_Vehicle_Population_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "088a4476-885e-4ee8-8977-8a32cb645a21",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Used to Build Schema"
    }
   },
   "outputs": [],
   "source": [
    "for x in df.schema:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4365800e-e51e-4377-bfa6-81a6d64e2021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_police = StructType(fields=[StructField('VIN (1-10)', StringType(), True)\n",
    "StructField('County', StringType(), True)\n",
    "StructField('City', StringType(), True)\n",
    "StructField('State', StringType(), True)\n",
    "StructField('Postal Code', StringType(), True)\n",
    "StructField('Model Year', StringType(), True)\n",
    "StructField('Make', StringType(), True)\n",
    "StructField('Model', StringType(), True)\n",
    "StructField('Electric Vehicle Type', StringType(), True)\n",
    "StructField('Clean Alternative Fuel Vehicle (CAFV) Eligibility', StringType(), True)\n",
    "StructField('Electric Range', StringType(), True)\n",
    "StructField('Base MSRP', StringType(), True)\n",
    "StructField('Legislative District', StringType(), True)\n",
    "StructField('DOL Vehicle ID', StringType(), True)\n",
    "StructField('Vehicle Location', StringType(), True)\n",
    "StructField('Electric Utility', StringType(), True)\n",
    "StructField('2020 Census Tract', StringType(), True)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9f4c91a-0298-4f00-bc8b-cb567cf2c6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f246db-560c-40d5-9bd9-f1e7b83ca79f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ed43439-58b1-4275-a87b-144bb64b6c22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "circuits_renamed_df = circuits_selected_df.withColumnRenamed(\"circuitId\", \"circuit_id\") \\\n",
    ".withColumnRenamed(\"circuitRef\", \"circuit_ref\") \\\n",
    ".withColumnRenamed(\"lat\", \"latitude\") \\\n",
    ".withColumnRenamed(\"lng\", \"longitude\") \\\n",
    ".withColumnRenamed(\"alt\", \"altitude\") \n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md \n",
    "# MAGIC ##### Step 4 - Add ingestion date to the dataframe\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "circuits_final_df = circuits_renamed_df.withColumn(\"ingestion_date\", current_timestamp()) \n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ##### Step 5 - Write data to datalake as parquet\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "circuits_final_df.write.mode(\"overwrite\").parquet(\"/mnt/formula1dl/processed/circuits\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "display(spark.read.parquet(\"/mnt/formula1dl/processed/circuits\"))\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest circuits.csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
